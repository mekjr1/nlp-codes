{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS_oogTbU6g5"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere\n",
        "# or \n",
        "logging.disable(logging.WARNING) # disable WARNING, INFO and DEBUG logging everywhere\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD__BgzqVMXS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-L6PfSjrVM9Q"
      },
      "outputs": [],
      "source": [
        "max_length = 128  # Maximum length of input sentence to the model.\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Labels in our dataset.\n",
        "labels = [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWJbr-suV5Jc"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('https://raw.githubusercontent.com/GIL-UNAM/PARMEX_2022/main/parmex_train.csv')\n",
        "print(\"Train Dataframe:\")\n",
        "train.head(3)\n",
        "print(f'Train dataframe contains {train.shape[0]} samples.')\n",
        "print('Number of features in train data : ', train.shape[1])\n",
        "print('Train Features : ', train.columns.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5if8AAH-r-_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh-OTlZPWfFY"
      },
      "outputs": [],
      "source": [
        "train_df,test_df=train_test_split(train,test_size=0.25,random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TqHTRTOZAse"
      },
      "outputs": [],
      "source": [
        "valid_df=test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMsIkbKMZaSF"
      },
      "outputs": [],
      "source": [
        "# Shape of the data\n",
        "print(f\"Total train samples : {train_df.shape[0]}\")\n",
        "print(f\"Total validation samples: {valid_df.shape[0]}\")\n",
        "print(f\"Total test samples: {valid_df.shape[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rdj1kEg5Z2Yh"
      },
      "outputs": [],
      "source": [
        "print(f\"Sentence1: {train_df.loc[1, 'Text1']}\")\n",
        "print(f\"Sentence2: {train_df.loc[1, 'Text2']}\")\n",
        "print(f\"Similarity: {train_df.loc[1, 'Label']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BIlfDgHZ8Bp"
      },
      "outputs": [],
      "source": [
        "train_df = (\n",
        "    train_df[train_df.Label != \"-\"]\n",
        "    .sample(frac=1.0, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "valid_df = (\n",
        "    valid_df[valid_df.Label != \"-\"]\n",
        "    .sample(frac=1.0, random_state=42)\n",
        "    .reset_index(drop=True)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrG04v41bj0-"
      },
      "outputs": [],
      "source": [
        "'''train_df[\"label\"] = train_df[\"similarity\"].apply(\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\n",
        ")'''\n",
        "y_train = tf.keras.utils.to_categorical(train_df.Label, num_classes=2)\n",
        "\n",
        "'''valid_df[\"label\"] = valid_df[\"similarity\"].apply(\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\n",
        ")'''\n",
        "y_val = tf.keras.utils.to_categorical(valid_df.Label, num_classes=2)\n",
        "\n",
        "'''test_df[\"label\"] = test_df[\"similarity\"].apply(\n",
        "    lambda x: 0 if x == \"contradiction\" else 1 if x == \"entailment\" else 2\n",
        ")'''\n",
        "y_test = tf.keras.utils.to_categorical(test_df.Label, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvVs9dCiDtuB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n",
        "tokenizer.save_pretrained('/content/drive/My Drive/tokenizer2/')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ1Wi-GBK8c9"
      },
      "outputs": [],
      "source": [
        "bert_model = transformers.TFBertModel.from_pretrained(\"hiiamsid/sentence_similarity_spanish_es\",from_pt=True)\n",
        "bert_model.save_pretrained('/content/drive/My Drive/tokenizer2/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwdeVd1Db6cU"
      },
      "outputs": [],
      "source": [
        "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Generates batches of data.\n",
        "\n",
        "    Args:\n",
        "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
        "        labels: Array of labels.\n",
        "        batch_size: Integer batch size.\n",
        "        shuffle: boolean, whether to shuffle the data.\n",
        "        include_targets: boolean, whether to incude the labels.\n",
        "\n",
        "    Returns:\n",
        "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
        "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
        "         if `include_targets=False`)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        sentence_pairs,\n",
        "        labels,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        include_targets=True,\n",
        "    ):\n",
        "        self.sentence_pairs = sentence_pairs\n",
        "        self.labels = labels\n",
        "        self.shuffle = shuffle\n",
        "        self.batch_size = batch_size\n",
        "        self.include_targets = include_targets\n",
        "        # Load our BERT Tokenizer to encode the text.\n",
        "        # We will use base-base-uncased pretrained model.\n",
        "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
        "            \"/content/drive/My Drive/tokenizer2/\", do_lower_case=True##################################################################################################\n",
        "        )\n",
        "        self.indexes = np.arange(len(self.sentence_pairs))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        # Denotes the number of batches per epoch.\n",
        "        return len(self.sentence_pairs) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieves the batch of index.\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        sentence_pairs = self.sentence_pairs[indexes]\n",
        "\n",
        "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
        "        # encoded together and separated by [SEP] token.\n",
        "        encoded = self.tokenizer.batch_encode_plus(\n",
        "            sentence_pairs.tolist(),\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=True,\n",
        "            return_token_type_ids=True,\n",
        "            pad_to_max_length=True,\n",
        "            return_tensors=\"tf\",\n",
        "        )\n",
        "\n",
        "        # Convert batch of encoded features to numpy array.\n",
        "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
        "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
        "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
        "\n",
        "        # Set to true if data generator is used for training/validation.\n",
        "        if self.include_targets:\n",
        "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
        "            return [input_ids, attention_masks, token_type_ids], labels\n",
        "        else:\n",
        "            return [input_ids, attention_masks, token_type_ids]\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
        "        if self.shuffle:\n",
        "            np.random.RandomState(42).shuffle(self.indexes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JwFXGTxCcD6K"
      },
      "outputs": [],
      "source": [
        "# Create the model under a distribution strategy scope.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with strategy.scope():\n",
        "    # Encoded token ids from BERT tokenizer.\n",
        "    input_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
        "    )\n",
        "    # Attention masks indicates to the model which tokens should be attended to.\n",
        "    attention_masks = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
        "    )\n",
        "    # Token type ids are binary masks identifying different sequences in the model.\n",
        "    token_type_ids = tf.keras.layers.Input(\n",
        "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
        "    )\n",
        "    # Loading pretrained BERT model.\n",
        "    bert_model = transformers.TFBertModel.from_pretrained(\"/content/drive/My Drive/tokenizer2/\")########################################################################\n",
        "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
        "    bert_model.trainable = False\n",
        "\n",
        "    bert_output = bert_model(\n",
        "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
        "    )\n",
        "    sequence_output = bert_output.last_hidden_state\n",
        "    pooled_output = bert_output.pooler_output\n",
        "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
        "    bi_lstm = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True)\n",
        "    )(sequence_output)\n",
        "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
        "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
        "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
        "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
        "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
        "    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n",
        "    model = tf.keras.models.Model(\n",
        "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"acc\"],\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"Strategy: {strategy}\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iVDCyrX2cOeJ"
      },
      "outputs": [],
      "source": [
        "train_data = BertSemanticDataGenerator(\n",
        "    train_df[[\"Text1\", \"Text2\"]].values.astype(\"str\"),\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        ")\n",
        "valid_data = BertSemanticDataGenerator(\n",
        "    valid_df[[\"Text1\", \"Text2\"]].values.astype(\"str\"),\n",
        "    y_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU6JSnGrdi5Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiHK3in2eYfz"
      },
      "outputs": [],
      "source": [
        "# Unfreeze the bert_model.\n",
        "bert_model.trainable = True\n",
        "# Recompile the model to make the change effective.\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NJGKr_ZzgL9Z",
        "outputId": "58dda6f3-0b63-4f09-c9b2-cb76f9740e92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "178/178 [==============================] - 341s 2s/step - loss: 0.1293 - accuracy: 0.9635 - val_loss: 0.1240 - val_accuracy: 0.9656\n",
            "Epoch 2/2\n",
            "178/178 [==============================] - 308s 2s/step - loss: 0.0956 - accuracy: 0.9717 - val_loss: 0.1216 - val_accuracy: 0.9656\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=valid_data,\n",
        "    epochs=epochs,\n",
        "    use_multiprocessing=True,\n",
        "    workers=-1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "50gCU6pQgPC_"
      },
      "outputs": [],
      "source": [
        "test_data = BertSemanticDataGenerator(\n",
        "    test_df[[\"Text1\", \"Text2\"]].values.astype(\"str\"),\n",
        "    y_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        ")\n",
        "model.evaluate(test_data, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jZRgUIcGgSIv"
      },
      "outputs": [],
      "source": [
        "def check_similarity(sentence1, sentence2):\n",
        "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
        "    test_data = BertSemanticDataGenerator(\n",
        "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
        "    )\n",
        "\n",
        "    proba = model.predict(test_data[0])[0]\n",
        "    idx = np.argmax(proba)\n",
        "    proba = f\"{proba[idx]: .2f}%\"\n",
        "    pred = labels[idx]\n",
        "    return pred, proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MzMmU_DCkuSV"
      },
      "outputs": [],
      "source": [
        "sentence1 = \"A smiling costumed woman is holding an umbrella\"\n",
        "sentence2 = \"A happy woman in a fairy costume holds an umbrella\"\n",
        "check_similarity(sentence1, sentence2)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZJI8x64llQ0Y"
      },
      "outputs": [],
      "source": [
        "test_dff=test_df.reset_index(drop=True)\n",
        "train_dff=train_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ob-wEYMkVT2",
        "outputId": "968a66f1-9b9d-451e-e8b0-755d68fb6296"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "ppp=[]\n",
        "for i in range(len(train_dff)):\n",
        "  \n",
        "  ppp.append(check_similarity(train_dff['Text1'][i], train_dff['Text2'][i])[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T1L2TXU8Y8hL"
      },
      "outputs": [],
      "source": [
        "train_dff['predictions'] = ppp\n",
        "train_dff.to_csv('misclassifyTrain.csv', header=True, index=False, columns=list(train_dff.axes[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WGWfZ3_IZS-c",
        "outputId": "aa9891c3-7e67-4b93-cbcb-8632602b05ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5c130178-f15f-4820-b6d0-db03b9f706ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text1</th>\n",
              "      <th>Text2</th>\n",
              "      <th>Label</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>los colores y el ánimo mexicano son factores fundamentales en esta época del año que resaltan lo especial de esta fecha.</td>\n",
              "      <td>una de las tradiciones más populares y que es un referente internacional sin duda es el día de muertos.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>una de las referencias escritas más tempranas sobre el uso del sushi en japón data del año 718 como parte de un tratado de leyes denominado yororitsuryo, en el se hace referencia al uso del sushi como forma de pago de impuestos.</td>\n",
              "      <td>al mezclarse el vinagre con el arroz el proceso de fermentar el pescado para obtener los olores y el sabor del nare sushi devino obsoleto.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>durante el período del imperio mongol que se expandió por el territorio chino, esta forma de conservar el pescado quedó parcialmente olvidada, quizás por ser las costumbres mongolas más carnívoras.</td>\n",
              "      <td>no era necesario usar estos métodos de conservar el pescado en las poblaciones de la costa porque el pescado lo tenían todo el año.</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>dentro, los frutos cocidos se mantienen calientes y, por consiguiente, listos para ser consumidos.</td>\n",
              "      <td>en su interior se guarda la temperatura adecuada para que estos platillos puedan ser comidos sin mayor preparación.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>existen 10 casas tequileras que se consideran las más importantes del país, tanto por su antigüedad e importancia en el mercado y dicha lista está encabezada por tequila josé cuervo.</td>\n",
              "      <td>debido a lo anterior, varios productores de diferentes zonas buscan aprovecharse del buen nombre que los productores originales han ganado con el tiempo.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>para su elaboración, primero se extraen azúcares contenidos en las piñas de agave y se separan de la fibra. después, se decide qué bebida se elaborará a partir de sus componentes.</td>\n",
              "      <td>aunque es diferente al mezcal y podría parecer que no tienen ninguna relación, gracias su elaboración, el tequila se considera como un tipo específico de mezcal.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>al ser una bebida distinta al mezcal, se cree que no tendría relación en aspectos de elaboración con el tequila, pero es considerado como un tipo específico de mezcal.</td>\n",
              "      <td>el destilado de agave que se utiliza para preparar el tequila se realiza solo en zonas específicas de méxico, por esta razón es un producto de origen registrado</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>la carne tradicional de este platillo es el cordero, pero depende de los gustos locales y prohibiciones religiosas, en la actualidad se prepara con carne de cordero, cabra, pollo, cerdo o pescado.</td>\n",
              "      <td>en irán, hay muchas variaciones del mismo platillo, y últimamente se ve que al cocinarlo también se usa pescado o pavo.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>con esta tradición, se busca rendir tributo a los antepasados familiares, a los difuntos cercanos o a personajes importantes.</td>\n",
              "      <td>usualmente, los altares están compuestos por varios niveles que representan la cosmovisión de quienes lo ponen variando la región en la que se hace, y conecta al mundo material con el inmaterial, cada nivel tiene un significado diferente.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>expresiones como cocina molecular o gastronomía molecular son más populares en los medios que en la hostelería.</td>\n",
              "      <td>este método consiste en hervir el líquido con baja presión y a temperatura baja con el fin de conservar las moléculas del sabor, una técnica usada inicialmente en laboratorios químicos que después se empleó en la cocina, inclusive puede extraer el suave aroma de los pétalos de rosa.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c130178-f15f-4820-b6d0-db03b9f706ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c130178-f15f-4820-b6d0-db03b9f706ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c130178-f15f-4820-b6d0-db03b9f706ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                    Text1  \\\n",
              "5                                                                                                                los colores y el ánimo mexicano son factores fundamentales en esta época del año que resaltan lo especial de esta fecha.   \n",
              "29   una de las referencias escritas más tempranas sobre el uso del sushi en japón data del año 718 como parte de un tratado de leyes denominado yororitsuryo, en el se hace referencia al uso del sushi como forma de pago de impuestos.   \n",
              "37                                  durante el período del imperio mongol que se expandió por el territorio chino, esta forma de conservar el pescado quedó parcialmente olvidada, quizás por ser las costumbres mongolas más carnívoras.   \n",
              "152                                                                                                                                    dentro, los frutos cocidos se mantienen calientes y, por consiguiente, listos para ser consumidos.   \n",
              "254                                                existen 10 casas tequileras que se consideran las más importantes del país, tanto por su antigüedad e importancia en el mercado y dicha lista está encabezada por tequila josé cuervo.   \n",
              "328                                                   para su elaboración, primero se extraen azúcares contenidos en las piñas de agave y se separan de la fibra. después, se decide qué bebida se elaborará a partir de sus componentes.   \n",
              "331                                                               al ser una bebida distinta al mezcal, se cree que no tendría relación en aspectos de elaboración con el tequila, pero es considerado como un tipo específico de mezcal.   \n",
              "346                                  la carne tradicional de este platillo es el cordero, pero depende de los gustos locales y prohibiciones religiosas, en la actualidad se prepara con carne de cordero, cabra, pollo, cerdo o pescado.   \n",
              "366                                                                                                         con esta tradición, se busca rendir tributo a los antepasados familiares, a los difuntos cercanos o a personajes importantes.   \n",
              "494                                                                                                                       expresiones como cocina molecular o gastronomía molecular son más populares en los medios que en la hostelería.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                           Text2  \\\n",
              "5                                                                                                                                                                                        una de las tradiciones más populares y que es un referente internacional sin duda es el día de muertos.   \n",
              "29                                                                                                                                                    al mezclarse el vinagre con el arroz el proceso de fermentar el pescado para obtener los olores y el sabor del nare sushi devino obsoleto.   \n",
              "37                                                                                                                                                           no era necesario usar estos métodos de conservar el pescado en las poblaciones de la costa porque el pescado lo tenían todo el año.   \n",
              "152                                                                                                                                                                          en su interior se guarda la temperatura adecuada para que estos platillos puedan ser comidos sin mayor preparación.   \n",
              "254                                                                                                                                    debido a lo anterior, varios productores de diferentes zonas buscan aprovecharse del buen nombre que los productores originales han ganado con el tiempo.   \n",
              "328                                                                                                                            aunque es diferente al mezcal y podría parecer que no tienen ninguna relación, gracias su elaboración, el tequila se considera como un tipo específico de mezcal.   \n",
              "331                                                                                                                             el destilado de agave que se utiliza para preparar el tequila se realiza solo en zonas específicas de méxico, por esta razón es un producto de origen registrado   \n",
              "346                                                                                                                                                                      en irán, hay muchas variaciones del mismo platillo, y últimamente se ve que al cocinarlo también se usa pescado o pavo.   \n",
              "366                                               usualmente, los altares están compuestos por varios niveles que representan la cosmovisión de quienes lo ponen variando la región en la que se hace, y conecta al mundo material con el inmaterial, cada nivel tiene un significado diferente.   \n",
              "494  este método consiste en hervir el líquido con baja presión y a temperatura baja con el fin de conservar las moléculas del sabor, una técnica usada inicialmente en laboratorios químicos que después se empleó en la cocina, inclusive puede extraer el suave aroma de los pétalos de rosa.   \n",
              "\n",
              "     Label  predictions  \n",
              "5        1            0  \n",
              "29       1            0  \n",
              "37       0            1  \n",
              "152      1            0  \n",
              "254      1            0  \n",
              "328      1            0  \n",
              "331      0            1  \n",
              "346      1            0  \n",
              "366      1            0  \n",
              "494      1            0  "
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mdf=train_dff[train_dff['Label'] != train_dff['predictions']]\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "mdf.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ib3XAWnqlDrA",
        "outputId": "faa76bfa-972d-4aa1-fe17-f2a9c65242eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99      4602\n",
            "           1       0.97      0.93      0.95      1098\n",
            "\n",
            "    accuracy                           0.98      5700\n",
            "   macro avg       0.98      0.96      0.97      5700\n",
            "weighted avg       0.98      0.98      0.98      5700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(train_dff.Label,ppp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8eztZLQoNpL"
      },
      "outputs": [],
      "source": [
        "ppp=[]\n",
        "for i in range(len(test_dff)):\n",
        "  ppp.append(check_similarity(test_dff['Text1'][i], test_dff['Text2'][i])[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGtCQ_wBhDCD"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_dff.Label,ppp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA8fllp7hLi8"
      },
      "outputs": [],
      "source": [
        "test_dff['predictions'] = ppp\n",
        "test_dff.to_csv('misclassify.csv', header=True, index=False, columns=list(test_dff.axes[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rb5WFZWaXlO5"
      },
      "outputs": [],
      "source": [
        "test_dff.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwhr4EdLW_2U"
      },
      "outputs": [],
      "source": [
        "mdf=test_dff[test_dff['Label'] != test_dff['predictions']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vX6OWrDjCz7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e3Cg-HQYGgo"
      },
      "outputs": [],
      "source": [
        "mdf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgOExjrrYnSV"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShcNM69HYLqK"
      },
      "outputs": [],
      "source": [
        "mdf.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fs84FbPiimZQ"
      },
      "outputs": [],
      "source": [
        "dt= pd.read_csv(\"/content/misclassifyTrain.csv\")\n",
        "dt1= pd.read_csv(\"/content/misclassify.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqdHBGN6Ng0C"
      },
      "outputs": [],
      "source": [
        "print(classification_report(dt.Label,dt.predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSiVflSzNtEc"
      },
      "outputs": [],
      "source": [
        "print(classification_report(dt1.Label,dt1.predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLkPOvtsNxuL"
      },
      "outputs": [],
      "source": [
        "dtx= pd.read_csv(\"misclassifyTrain2.csv\")\n",
        "dtx1= pd.read_csv(\"misclassify2.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U60HqlXkOInl"
      },
      "outputs": [],
      "source": [
        "print(classification_report(dtx.Label,dtx.predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxJ_W_NMOKFm"
      },
      "outputs": [],
      "source": [
        "print(classification_report(dtx1.Label,dtx1.predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTX-5S0oi4K0"
      },
      "outputs": [],
      "source": [
        "dt.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcuHfI-0i6q2"
      },
      "outputs": [],
      "source": [
        "dt1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVrPxyx2jEGh"
      },
      "outputs": [],
      "source": [
        "fp=dt[dt['Label'] != dt['predictions']]\n",
        "fptest=dt1[dt1['Label'] != dt1['predictions']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4YMXczAjR-e"
      },
      "outputs": [],
      "source": [
        "fp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlhOAQ6HjUCF"
      },
      "outputs": [],
      "source": [
        "fptest.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q8tqjgYjVzN"
      },
      "outputs": [],
      "source": [
        "fp.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1XC7zWhjYRB"
      },
      "outputs": [],
      "source": [
        "fptest.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZAnEdjrjtBH"
      },
      "outputs": [],
      "source": [
        "dups_color = train_df.pivot_table(columns=['Text1'], aggfunc='size')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRiDTh9Xk2mX"
      },
      "outputs": [],
      "source": [
        "dups_color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0nBswCJl49M"
      },
      "outputs": [],
      "source": [
        "v = train_df.Text1.value_counts()\n",
        "train_df[train_df.Text1.isin(v.index[v.gt(100)])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b1wRgWgnohZ"
      },
      "outputs": [],
      "source": [
        "dups.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ulka7-__Cg8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv(\"misclassify.csv\")\n",
        "train = pd.read_csv(\"misclassifyTrain.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBGOUsLR_eCi"
      },
      "outputs": [],
      "source": [
        "fp=train[train['Label'] != train['predictions']]\n",
        "fptest=test[test['Label'] != test['predictions']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR_DCfxu_tvO"
      },
      "outputs": [],
      "source": [
        "fp.to_csv(\"misclassTrain.csv\")\n",
        "fptest.to_csv(\"misclassTest.csv\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzDhW0LlAKHy"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "fp.head(20)\n",
        "fptest.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1HYCRXGj-Ps"
      },
      "source": [
        "sentence-transformers/bert-base-nli-mean-tokens:\n",
        "  Train set: 0.95 M_F1\n",
        "  Test set: 0.91"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Fazl Code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}